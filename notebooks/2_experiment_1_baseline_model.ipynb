{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d3f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00b72b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f8ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run thoughtful-fowl-656 at: http://ec2-13-61-4-77.eu-north-1.compute.amazonaws.com:5000/#/experiments/0/runs/8524b3e063b14341b535c791acfc08ff\n",
      "üß™ View experiment at: http://ec2-13-61-4-77.eu-north-1.compute.amazonaws.com:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Test mlflow\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://ec2-13-61-4-77.eu-north-1.compute.amazonaws.com:5000/\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 15)\n",
    "    mlflow.log_metric(\"metric1\", 0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3873d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/malcolmosh/goodbooks-10k/master/books_enriched.csv\",\n",
    "    index_col=[0],\n",
    "    converters={\"genres\": literal_eval, \"authors\": literal_eval},\n",
    ")\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/malcolmosh/goodbooks-10k/master/ratings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f17e400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users:  53424\n"
     ]
    }
   ],
   "source": [
    "print(\"number of users: \", ratings[\"user_id\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bfafd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'authors', 'average_rating', 'best_book_id', 'book_id',\n",
       "       'books_count', 'description', 'genres', 'goodreads_book_id',\n",
       "       'image_url', 'isbn', 'isbn13', 'language_code',\n",
       "       'original_publication_year', 'original_title', 'pages', 'publishDate',\n",
       "       'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5',\n",
       "       'ratings_count', 'small_image_url', 'title', 'work_id',\n",
       "       'work_ratings_count', 'work_text_reviews_count', 'authors_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85052ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[\n",
    "    [\"book_id\", \"title\", \"description\", \"authors\", \"genres\", \"average_rating\", \"ratings_count\"]\n",
    "    ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760544a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>genres</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n",
       "      <td>[Suzanne Collins]</td>\n",
       "      <td>[young-adult, fiction, fantasy, science-fictio...</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>Harry Potter's life is miserable. His parents ...</td>\n",
       "      <td>[J.K. Rowling, Mary GrandPr√©]</td>\n",
       "      <td>[fantasy, fiction, young-adult, classics]</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4602479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "      <td>About three things I was absolutely positive.\\...</td>\n",
       "      <td>[Stephenie Meyer]</td>\n",
       "      <td>[young-adult, fantasy, romance, fiction, paran...</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3866839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>[Harper Lee]</td>\n",
       "      <td>[classics, fiction, historical-fiction, young-...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3198671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>Alternate Cover Edition ISBN: 0743273567 (ISBN...</td>\n",
       "      <td>[F. Scott Fitzgerald]</td>\n",
       "      <td>[classics, fiction, historical-fiction, romance]</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2683664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                              title  \\\n",
       "0        1            The Hunger Games (The Hunger Games, #1)   \n",
       "1        2  Harry Potter and the Sorcerer's Stone (Harry P...   \n",
       "2        3                            Twilight (Twilight, #1)   \n",
       "3        4                              To Kill a Mockingbird   \n",
       "4        5                                   The Great Gatsby   \n",
       "\n",
       "                                         description  \\\n",
       "0  WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...   \n",
       "1  Harry Potter's life is miserable. His parents ...   \n",
       "2  About three things I was absolutely positive.\\...   \n",
       "3  The unforgettable novel of a childhood in a sl...   \n",
       "4  Alternate Cover Edition ISBN: 0743273567 (ISBN...   \n",
       "\n",
       "                         authors  \\\n",
       "0              [Suzanne Collins]   \n",
       "1  [J.K. Rowling, Mary GrandPr√©]   \n",
       "2              [Stephenie Meyer]   \n",
       "3                   [Harper Lee]   \n",
       "4          [F. Scott Fitzgerald]   \n",
       "\n",
       "                                              genres  average_rating  \\\n",
       "0  [young-adult, fiction, fantasy, science-fictio...            4.34   \n",
       "1          [fantasy, fiction, young-adult, classics]            4.44   \n",
       "2  [young-adult, fantasy, romance, fiction, paran...            3.57   \n",
       "3  [classics, fiction, historical-fiction, young-...            4.25   \n",
       "4   [classics, fiction, historical-fiction, romance]            3.89   \n",
       "\n",
       "   ratings_count  \n",
       "0        4780653  \n",
       "1        4602479  \n",
       "2        3866839  \n",
       "3        3198671  \n",
       "4        2683664  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5173cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4\n",
       "2        2      260       5\n",
       "3        2     9296       5\n",
       "4        2     2318       3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7d7f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': <tf.Tensor: shape=(), dtype=int32, numpy=1>, 'book_id': <tf.Tensor: shape=(), dtype=int32, numpy=258>, 'rating': <tf.Tensor: shape=(), dtype=int32, numpy=5>}\n",
      "{'user_id': <tf.Tensor: shape=(), dtype=int32, numpy=2>, 'book_id': <tf.Tensor: shape=(), dtype=int32, numpy=4081>, 'rating': <tf.Tensor: shape=(), dtype=int32, numpy=4>}\n",
      "{'user_id': <tf.Tensor: shape=(), dtype=int32, numpy=2>, 'book_id': <tf.Tensor: shape=(), dtype=int32, numpy=260>, 'rating': <tf.Tensor: shape=(), dtype=int32, numpy=5>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 13:57:36.854256: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ratings_tf = tf.data.Dataset.from_tensor_slices(ratings.to_dict(\"list\"))\n",
    "for x in ratings_tf.take(3):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce529e7",
   "metadata": {},
   "source": [
    "**Query Tower**\n",
    "\n",
    "User Model representing User and his reading history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efab04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UserTower(tf.keras.Model):\n",
    "    def __init__(self, unique_book_ids, num_tokens, embedding_matrix, \n",
    "                 user_emb_dim=32, dropout_rate=0.2):\n",
    "        super(UserTower, self).__init__()\n",
    "\n",
    "        self.book_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.IntegerLookup(\n",
    "                vocabulary=unique_book_ids, \n",
    "                oov_token=num_tokens - 1,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim=num_tokens,\n",
    "                output_dim=embedding_matrix.shape[1],  # 1536 for OpenAI embeddings\n",
    "                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                trainable=False,  # freeze OpenAI vectors\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=8,\n",
    "            key_dim=embedding_matrix.shape[1] + 1,  # 1536 embedding + 1 rating\n",
    "        )\n",
    "        self.pooling = tf.keras.layers.GlobalAveragePooling1D()\n",
    "\n",
    "        self.final_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(user_emb_dim)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_history = inputs[\"user_history\"]\n",
    "        history_ratings = inputs[\"history_ratings\"]\n",
    "\n",
    "        history_emb = self.book_embedding(user_history)  # (batch, seq_len, 1536)\n",
    "\n",
    "        mean_rating = tf.reduce_mean(history_ratings, axis=1, keepdims=True)  # (batch, 1)\n",
    "        norm_ratings = history_ratings - mean_rating  # (batch, seq_len)\n",
    "        ratings_expanded = tf.expand_dims(norm_ratings, -1)  # (batch, seq_len, 1)\n",
    "        concat_input = tf.concat([history_emb, ratings_expanded], axis=-1)  # (batch, seq_len, 1537)\n",
    "\n",
    "        attn_out = self.attention(concat_input, concat_input)\n",
    "\n",
    "        pooled = self.pooling(attn_out)\n",
    "\n",
    "        user_emb = self.final_layers(pooled)\n",
    "\n",
    "        return user_emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef878c18",
   "metadata": {},
   "source": [
    "**Testing user tower**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbaa6944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User embeddings shape: (1, 32)\n",
      "User embeddings: [[-9.9997129e-04 -1.7348172e-04  3.2667897e-04 -2.4285991e-04\n",
      "  -4.4389372e-04  7.6807063e-04  1.0735486e-03  1.1163257e-04\n",
      "  -9.2693226e-04 -1.8707567e-04  5.2680302e-04  4.9088581e-04\n",
      "  -3.3586338e-04  1.5380569e-03 -2.1850027e-04  1.9180549e-03\n",
      "   1.6392160e-03 -1.0483534e-03  2.8725556e-04  1.5963594e-04\n",
      "  -7.3438301e-04  7.1609538e-05 -7.0786203e-04  7.1581890e-05\n",
      "  -1.0429180e-03  7.2478200e-04  3.6984694e-04 -5.5364775e-04\n",
      "  -6.6615554e-05 -1.5791173e-03 -1.5890929e-04  1.2531534e-03]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "    data = {\n",
    "        \"user_history\": [1, 2, 3],\n",
    "        \"history_ratings\": [4, 5, 3],\n",
    "    }\n",
    "    embedding_matrix = np.load(\"../src/data/embeddings_matrix.npy\")\n",
    "    num_books, embedding_dim = embedding_matrix.shape\n",
    "    unique_book_ids = np.arange(num_books - 1)\n",
    "\n",
    "\n",
    "    user_tower = UserTower(\n",
    "        unique_book_ids=unique_book_ids,\n",
    "        num_tokens=num_books,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "    )\n",
    "\n",
    "    example = {\n",
    "        \"user_history\": tf.constant([data[\"user_history\"]], dtype=tf.int32),\n",
    "        \"history_ratings\": tf.constant([data[\"history_ratings\"]], dtype=tf.float32),\n",
    "    }\n",
    "\n",
    "    user_embeddings = user_tower(example)\n",
    "\n",
    "    print(\"\\nUser embeddings shape:\", user_embeddings.shape)\n",
    "    print(\"User embeddings:\", user_embeddings.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07416c4",
   "metadata": {},
   "source": [
    "**Candidate Tower**\n",
    "\n",
    "Book Model representing books and its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f070f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemTower(tf.keras.Model):\n",
    "    def __init__(self, unique_book_ids, num_tokens, embedding_matrix, user_emb_dim=32, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.vocabulary = unique_book_ids\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "\n",
    "        self.book_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.IntegerLookup(\n",
    "                vocabulary=unique_book_ids, \n",
    "                oov_token=num_books - 1,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim=num_tokens,\n",
    "                output_dim=embedding_matrix.shape[1],  \n",
    "                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                trainable=False,  \n",
    "            )\n",
    "        ])\n",
    "                \n",
    "        self.final_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(user_emb_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        item_embedding = self.book_embedding(inputs[\"book_id\"])\n",
    "        rating = tf.expand_dims(inputs[\"avg_rating\"], -1) \n",
    "        concat_input = tf.concat([item_embedding, rating], axis=-1)\n",
    "        item_emb = self.final_layers(concat_input)\n",
    "        return item_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f0d99",
   "metadata": {},
   "source": [
    "**Testing candidate tower**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf13d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Book embeddings shape: (1, 32)\n",
      "Book embeddings: [[ 0.09775109 -0.07769852  0.05263288 -0.03646014 -0.05195387  0.01323555\n",
      "   0.11356245 -0.00553065 -0.06013871 -0.12366802 -0.13854872 -0.00403975\n",
      "   0.02192115  0.24883085 -0.12797149  0.09379776  0.03131978 -0.03375912\n",
      "  -0.01381343  0.14757746 -0.02357512  0.05439571 -0.1077126  -0.0903956\n",
      "   0.11584894 -0.01130453 -0.06477856 -0.09171694  0.10833809 -0.02485837\n",
      "   0.09170313 -0.1164398 ]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = {\n",
    "        \"book_id\": [1],\n",
    "        \"avg_rating\": [4],\n",
    "    }\n",
    "    embedding_matrix = np.load(\"../src/data/embeddings_matrix.npy\")\n",
    "    num_books, embedding_dim = embedding_matrix.shape\n",
    "    unique_book_ids = np.arange(num_books - 1)\n",
    "\n",
    "    book_tower = ItemTower(\n",
    "        unique_book_ids=unique_book_ids,\n",
    "        num_tokens=num_books,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "    )\n",
    "\n",
    "    example = {\n",
    "        \"book_id\": tf.constant(data[\"book_id\"], dtype=tf.int32), \n",
    "        \"avg_rating\": tf.constant(data[\"avg_rating\"], dtype=tf.float32),\n",
    "    }\n",
    "\n",
    "    book_embeddings = book_tower(example)\n",
    "\n",
    "    print(\"\\Book embeddings shape:\", book_embeddings.shape)\n",
    "    print(\"Book embeddings:\", book_embeddings.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f61926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query book: The Great Gatsby\n",
      "\n",
      "Top similar books:\n",
      "- Babbitt (cosine similarity: 0.652)\n",
      "- Jaws (cosine similarity: 0.635)\n",
      "- David and Goliath: Underdogs, Misfits, and the Art of Battling Giants (cosine similarity: 0.548)\n",
      "- The House of Thunder (cosine similarity: 0.543)\n",
      "- Gone with the Wind (cosine similarity: 0.531)\n"
     ]
    }
   ],
   "source": [
    "id_to_title = dict(zip(books['book_id'], books['title']))\n",
    "\n",
    "# Choose a query book\n",
    "query_id = 5\n",
    "query_title = id_to_title[query_id]\n",
    "query_emb = embedding_matrix[query_id]\n",
    "\n",
    "# Normalize embeddings\n",
    "emb_norm = embedding_matrix / np.linalg.norm(embedding_matrix, axis=1, keepdims=True)\n",
    "query_emb_norm = query_emb / np.linalg.norm(query_emb)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cos_sim = np.dot(emb_norm, query_emb_norm)\n",
    "\n",
    "# Get top-k similar books (excluding the query itself)\n",
    "top_k = 5\n",
    "top_k_idx = np.argsort(-cos_sim)\n",
    "top_k_idx = top_k_idx[top_k_idx != query_id][:top_k]\n",
    "\n",
    "# Print results\n",
    "print(f\"Query book: {query_title}\\n\")\n",
    "print(\"Top similar books:\")\n",
    "for idx in top_k_idx:\n",
    "    print(f\"- {id_to_title[idx]} (cosine similarity: {cos_sim[idx]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332853c0",
   "metadata": {},
   "source": [
    "**Two Tower Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4904d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRetrievalModel(tfrs.models.Model):\n",
    "    def __init__(self, user_tower, item_tower, candidates_ds):\n",
    "        super().__init__()\n",
    "        self.user_tower = user_tower\n",
    "        self.item_tower = item_tower\n",
    "\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=candidates_ds.map(item_tower)\n",
    "    )\n",
    ")\n",
    "    def call(self, features):\n",
    "        user_embeddings = self.user_tower({\n",
    "            \"user_history\": features[\"user_history\"],\n",
    "            \"history_ratings\": features[\"history_ratings\"]\n",
    "        })\n",
    "\n",
    "        book_embeddings = self.item_tower({\n",
    "            \"book_id\": features[\"book_id\"],\n",
    "            \"avg_rating\": features[\"avg_rating\"]\n",
    "        })\n",
    "\n",
    "        return user_embeddings, book_embeddings\n",
    "\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings, book_embeddings = self(features)\n",
    "        return self.task(user_embeddings, book_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b840da",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ae5a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/fx/q2jpnwkd2dn90t8tdh1jxffm0000gn/T/ipykernel_1101/2533484925.py:32: group_by_window (from tensorflow.python.data.experimental.ops.grouping) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.group_by_window(...)`.\n",
      "{'user_history': TensorShape([128, 175]), 'history_ratings': TensorShape([128, 175]), 'book_id': TensorShape([128]), 'avg_rating': TensorShape([128])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 21:06:32.345613: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.merge(\n",
    "    books[[\"book_id\", \"average_rating\"]],\n",
    "    on=\"book_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "ratings_tf = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": ratings[\"user_id\"].values.astype(\"int32\"),\n",
    "    \"book_id\": ratings[\"book_id\"].values.astype(\"int32\"),\n",
    "    \"rating\":  ratings[\"rating\"].values.astype(\"float32\"),\n",
    "    \"avg_rating\": ratings[\"average_rating\"].values.astype(\"float32\"),\n",
    "})\n",
    "\n",
    "users = ratings[\"user_id\"].unique()\n",
    "train_cut = int(0.8 * len(users))\n",
    "train_users = tf.constant(users[:train_cut], dtype=tf.int32)\n",
    "val_users   = tf.constant(users[train_cut:], dtype=tf.int32)\n",
    "\n",
    "train_filter = lambda x: tf.reduce_any(tf.equal(x[\"user_id\"], train_users))\n",
    "val_filter   = lambda x: tf.reduce_any(tf.equal(x[\"user_id\"], val_users))\n",
    "\n",
    "book_avg = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=books[\"book_id\"].values.astype(\"int32\"),\n",
    "        values=books[\"average_rating\"].values.astype(\"float32\"),\n",
    "    ),\n",
    "    default_value=0.0,\n",
    ")\n",
    "\n",
    "def group_by_user(ds):\n",
    "    return ds.apply(\n",
    "        tf.data.experimental.group_by_window(\n",
    "            key_func=lambda x: tf.cast(x[\"user_id\"], tf.int64),\n",
    "            reduce_func=lambda _, ds: ds.batch(1000), \n",
    "            window_size=1000,\n",
    "        )\n",
    "    )\n",
    "\n",
    "def make_example(batch):\n",
    "    book_ids = batch[\"book_id\"]\n",
    "    ratings = batch[\"rating\"]\n",
    "\n",
    "    n = tf.shape(book_ids)[0]\n",
    "\n",
    "    def make_valid():\n",
    "        history = {\n",
    "            \"user_history\": book_ids[:-1],\n",
    "            \"history_ratings\": ratings[:-1],\n",
    "            \"book_id\": book_ids[-1],\n",
    "            \"avg_rating\": batch[\"avg_rating\"][-1],\n",
    "        }\n",
    "        return tf.data.Dataset.from_tensors(history)\n",
    "\n",
    "    def too_short():\n",
    "        empty = {\n",
    "            \"user_history\": tf.constant([], dtype=tf.int32),\n",
    "            \"history_ratings\": tf.constant([], dtype=tf.float32),\n",
    "            \"book_id\": tf.constant(0, dtype=tf.int32),\n",
    "            \"avg_rating\": tf.constant(0.0, dtype=tf.float32),\n",
    "        }\n",
    "        return tf.data.Dataset.from_tensors(empty).take(0)\n",
    "\n",
    "    return tf.cond(n < 2, too_short, make_valid)\n",
    "\n",
    "\n",
    "train_ds = (\n",
    "    group_by_user(ratings_tf.filter(train_filter))\n",
    "    .flat_map(make_example)\n",
    "    .padded_batch(\n",
    "        128,\n",
    "        padded_shapes={\n",
    "            \"user_history\": [None],\n",
    "            \"history_ratings\": [None],\n",
    "            \"book_id\": [],\n",
    "            \"avg_rating\": [],\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    group_by_user(ratings_tf.filter(val_filter))\n",
    "    .flat_map(make_example)\n",
    "    .padded_batch(\n",
    "        128,\n",
    "        padded_shapes={\n",
    "            \"user_history\": [None],\n",
    "            \"history_ratings\": [None],\n",
    "            \"book_id\": [],\n",
    "            \"avg_rating\": [],\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "candidates_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"book_id\": books[\"book_id\"].values.astype(\"int32\"),\n",
    "    \"avg_rating\": books[\"average_rating\"].values.astype(\"float32\"),\n",
    "}).batch(128)\n",
    "\n",
    "for batch in train_ds.take(1):\n",
    "    print({k: v.shape for k, v in batch.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635a1da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: dict_keys(['user_history', 'history_ratings', 'book_id', 'avg_rating'])\n",
      "\n",
      "User history (first example):\n",
      "[ 258  268 5556 3638 1796  867   47 2738 4691  238 2063  916 4614  111\n",
      "   11 1644 3889  136 6665  150   35   33   60  148   10   94    4  492\n",
      "   57 1521   70   42  103   36  138  119   32   13   66 3406 2002   43\n",
      "  287 1041   45   38   67   46   22  115   31   16  132   40  407  256\n",
      "  273  378  329   98  216 1176  140  869 2679 1310  414   54   85  219\n",
      "  177  109  131  102   95  225   76  100  171  179  255  485  325  498\n",
      "  323  162   72  233  496  306  354 1030 1055 2770  198 1761 1942  128\n",
      "   81 5191 1187 2535 3294 4893 1180 6285 2133 1011  262  437  421  143\n",
      "  142  642  901  212    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "Shape: (175,)\n",
      "\n",
      "History ratings (first example):\n",
      "[5. 3. 3. 3. 5. 3. 3. 3. 4. 2. 4. 3. 1. 3. 5. 5. 3. 5. 4. 3. 5. 4. 3. 3.\n",
      " 4. 1. 5. 2. 3. 5. 5. 3. 3. 4. 2. 3. 4. 4. 4. 2. 5. 4. 3. 5. 5. 2. 3. 4.\n",
      " 3. 3. 4. 3. 3. 2. 2. 3. 3. 3. 4. 3. 3. 4. 3. 4. 3. 4. 4. 3. 3. 4. 5. 3.\n",
      " 4. 5. 4. 4. 3. 4. 3. 2. 1. 4. 3. 4. 3. 4. 3. 4. 3. 3. 3. 4. 4. 4. 4. 4.\n",
      " 3. 5. 5. 4. 5. 5. 5. 3. 4. 4. 5. 4. 3. 4. 5. 5. 4. 4. 4. 3. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n",
      "Shape: (175,)\n",
      "\n",
      "Target book ID (first example):\n",
      "231\n",
      "\n",
      "Target book avg rating (first example):\n",
      "4.14\n"
     ]
    }
   ],
   "source": [
    "for batch in train_ds.take(1):\n",
    "    print(\"Batch keys:\", batch.keys())  \n",
    "\n",
    "    print(\"\\nUser history (first example):\")\n",
    "    print(batch['user_history'][0].numpy()) \n",
    "    print(\"Shape:\", batch['user_history'][0].shape)\n",
    "\n",
    "    print(\"\\nHistory ratings (first example):\")\n",
    "    print(batch['history_ratings'][0].numpy())\n",
    "    print(\"Shape:\", batch['history_ratings'][0].shape)\n",
    "\n",
    "    print(\"\\nTarget book ID (first example):\")\n",
    "    print(batch['book_id'][0].numpy())\n",
    "\n",
    "    print(\"\\nTarget book avg rating (first example):\")\n",
    "    print(batch['avg_rating'][0].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "048bd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://ec2-13-61-4-77.eu-north-1.compute.amazonaws.com:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2be0f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-artifacts-123456789012-us-east-1/1', creation_time=1757249478539, experiment_id='1', last_update_time=1757249478539, lifecycle_stage='active', name='TTM Baseline', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"TTM Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b539e39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (1.40.25)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.25 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from boto3) (1.40.25)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from boto3) (0.13.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.25->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.25->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.25->boto3) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b650c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: awscli in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (1.42.25)\n",
      "Requirement already satisfied: botocore==1.40.25 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from awscli) (1.40.25)\n",
      "Requirement already satisfied: docutils<=0.19,>=0.18.1 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from awscli) (0.19)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from awscli) (0.13.1)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from awscli) (6.0.2)\n",
      "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from awscli) (0.4.6)\n",
      "Requirement already satisfied: rsa<4.8,>=3.1.2 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from awscli) (4.7.2)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore==1.40.25->awscli) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore==1.40.25->awscli) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore==1.40.25->awscli) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.40.25->awscli) (1.17.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95f10b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "528cf2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Access Key ID [None]: ^C\n"
     ]
    }
   ],
   "source": [
    "!aws configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:1484: UserWarning: Layer 'item_tower_6' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''module 'keras' has no attribute 'KerasTensor'''\n",
      "  warnings.warn(\n",
      "/Users/marysiapacocha/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'item_tower_6', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Exception encountered when calling ItemTower.call().\n\n\u001b[1mmodule 'keras' has no attribute 'KerasTensor'\u001b[0m\n\nArguments received by ItemTower.call():\n  ‚Ä¢ inputs={'book_id': 'tf.Tensor(shape=(None,), dtype=int32)', 'avg_rating': 'tf.Tensor(shape=(None,), dtype=float32)'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m item_tower\u001b[38;5;241m.\u001b[39mrating_norm\u001b[38;5;241m.\u001b[39madapt(all_avg_ratings)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Build two-tower model\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBookRetrievalModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_tower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_tower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidates_ds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Compile\u001b[39;00m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     34\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdagrad(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m     35\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m     ],\n\u001b[1;32m     41\u001b[0m )\n",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m, in \u001b[0;36mBookRetrievalModel.__init__\u001b[0;34m(self, user_tower, item_tower, candidates_ds)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_tower \u001b[38;5;241m=\u001b[39m user_tower\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_tower \u001b[38;5;241m=\u001b[39m item_tower\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m=\u001b[39m tfrs\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mRetrieval(\n\u001b[1;32m      8\u001b[0m     metrics\u001b[38;5;241m=\u001b[39mtfrs\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mFactorizedTopK(\n\u001b[0;32m----> 9\u001b[0m         candidates\u001b[38;5;241m=\u001b[39m\u001b[43mcandidates_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_tower\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     )\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2341\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m   2336\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2338\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2339\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2342\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2346\u001b[0m \u001b[43m    \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_unbounded_threadpool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2349\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:43\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, synchronous, use_unbounded_threadpool, name)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m debug_mode\u001b[38;5;241m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     39\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`num_parallel_calls` argument is specified.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     42\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m      \u001b[49m\u001b[43mforce_synchronous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msynchronous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m synchronous:\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:157\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, force_synchronous, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality \u001b[38;5;241m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force_synchronous \u001b[38;5;241m=\u001b[39m force_synchronous\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    259\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    262\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 265\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1256\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1255\u001b[0m   \u001b[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m   concrete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_concrete_function_garbage_collected\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1257\u001b[0m   concrete\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1258\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m concrete\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1226\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1224\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m     initializers \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_initializers_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_uninitialized_variables(initializers)\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m   1230\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m   \u001b[38;5;66;03m# version which is guaranteed to never create variables.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001b[0m, in \u001b[0;36mFunction._initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_scoped_tracing_options(\n\u001b[1;32m    692\u001b[0m     variable_capturing_scope,\n\u001b[1;32m    693\u001b[0m     tracing_compilation\u001b[38;5;241m.\u001b[39mScopeType\u001b[38;5;241m.\u001b[39mVARIABLE_CREATION,\n\u001b[1;32m    694\u001b[0m )\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# Force the definition of the function for these arguments\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvalid_creator_scope\u001b[39m(\u001b[38;5;241m*\u001b[39munused_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwds):\n\u001b[1;32m    701\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m   target_func_type \u001b[38;5;241m=\u001b[39m lookup_func_type\n\u001b[0;32m--> 283\u001b[0m concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_create_concrete_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlookup_func_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    288\u001b[0m   tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m    289\u001b[0m       concrete_function, current_func_context\n\u001b[1;32m    290\u001b[0m   )\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001b[0m, in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    303\u001b[0m   placeholder_bound_args \u001b[38;5;241m=\u001b[39m function_type\u001b[38;5;241m.\u001b[39mplaceholder_arguments(\n\u001b[1;32m    304\u001b[0m       placeholder_context\n\u001b[1;32m    305\u001b[0m   )\n\u001b[1;32m    307\u001b[0m disable_acd \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39mattributes \u001b[38;5;129;01mand\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mattributes\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m    308\u001b[0m     attributes_lib\u001b[38;5;241m.\u001b[39mDISABLE_ACD, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    309\u001b[0m )\n\u001b[0;32m--> 310\u001b[0m traced_func_graph \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplaceholder_bound_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_control_dependencies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdisable_acd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction_type_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_arg_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_placeholders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m transform\u001b[38;5;241m.\u001b[39mapply_func_graph_transforms(traced_func_graph)\n\u001b[1;32m    324\u001b[0m graph_capture_container \u001b[38;5;241m=\u001b[39m traced_func_graph\u001b[38;5;241m.\u001b[39mfunction_captures\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/framework/func_graph.py:1060\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m   1059\u001b[0m _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[0;32m-> 1060\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001b[0m, in \u001b[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    596\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[1;32m    597\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[0;32m--> 599\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[0;32m--> 231\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    232\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[1;32m    233\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[1;32m    160\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[0;32m--> 161\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m ret \u001b[38;5;241m=\u001b[39m variable_utils\u001b[38;5;241m.\u001b[39mconvert_variables_to_tensors(ret)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:690\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[0;32m--> 690\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    692\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:377\u001b[0m, in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39muser_requested \u001b[38;5;129;01mand\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mis_allowlisted(f):\n\u001b[0;32m--> 377\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_call_unconverted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# things like builtins.\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m options\u001b[38;5;241m.\u001b[39minternal_convert_user_code:\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:459\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mcall(args, kwargs)\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 459\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/Desktop/goodreads-recs-extension/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn[27], line 32\u001b[0m, in \u001b[0;36mItemTower.call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     30\u001b[0m item_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook_embedding(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     31\u001b[0m rating \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mexpand_dims(inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_rating\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch_size, 1)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m rating_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrating_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrating\u001b[49m\u001b[43m)\u001b[49m             \u001b[38;5;66;03m# normalized rating\u001b[39;00m\n\u001b[1;32m     33\u001b[0m concat_input \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconcat([item_embedding, rating_norm], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     34\u001b[0m item_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_layers(concat_input)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Exception encountered when calling ItemTower.call().\n\n\u001b[1mmodule 'keras' has no attribute 'KerasTensor'\u001b[0m\n\nArguments received by ItemTower.call():\n  ‚Ä¢ inputs={'book_id': 'tf.Tensor(shape=(None,), dtype=int32)', 'avg_rating': 'tf.Tensor(shape=(None,), dtype=float32)'}"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "embedding_matrix = np.load(\"../src/data/embeddings_matrix.npy\")\n",
    "num_books, embedding_dim = embedding_matrix.shape\n",
    "unique_book_ids = np.arange(num_books - 1)\n",
    "\n",
    "user_tower = UserTower(\n",
    "    unique_book_ids=unique_book_ids,\n",
    "    num_tokens=num_books,\n",
    "    embedding_matrix=embedding_matrix,\n",
    ")\n",
    "item_tower = ItemTower(\n",
    "    unique_book_ids=unique_book_ids,\n",
    "    num_tokens=num_books,\n",
    "    embedding_matrix=embedding_matrix,\n",
    ")\n",
    "min_rating = 1.0\n",
    "max_rating = 5.0\n",
    "\n",
    "def normalize_rating(batch):\n",
    "    batch[\"avg_rating\"] = (batch[\"avg_rating\"] - min_rating) / (max_rating - min_rating)\n",
    "    return batch\n",
    "\n",
    "# Apply to the dataset\n",
    "train_ds = train_ds.map(normalize_rating)\n",
    "val_ds = val_ds.map(normalize_rating)\n",
    "candidates_ds = candidates_ds.map(normalize_rating)\n",
    "\n",
    "model = BookRetrievalModel(user_tower, item_tower, candidates_ds)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.Precision(name=\"precision\"),\n",
    "        tf.keras.metrics.Recall(name=\"recall\"),\n",
    "        tf.keras.metrics.Accuracy(name=\"accuracy\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "mlflow_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: [\n",
    "        mlflow.log_metric(name, value, step=epoch) for name, value in logs.items()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def compute_recall_at_k(model, test_users, true_items, k=10):\n",
    "    user_embs = model.user_model(test_users)        # shape: (n_users, emb_dim)\n",
    "    item_embs = model.item_model(np.arange(num_books))  # shape: (n_items, emb_dim)\n",
    "\n",
    "    scores = tf.linalg.matmul(user_embs, item_embs, transpose_b=True)  # similarity\n",
    "    top_k = tf.math.top_k(scores, k=k).indices.numpy()                 # top-k item IDs\n",
    "\n",
    "    hits = 0\n",
    "    for i, true_item in enumerate(true_items):\n",
    "        if true_item in top_k[i]:\n",
    "            hits += 1\n",
    "    return hits / len(test_users)\n",
    "\n",
    "\n",
    "with mlflow.start_run(run_name=\"two_tower_model_experiment\"):\n",
    "\n",
    "    mlflow.log_param(\"optimizer\", \"Adagrad\")\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"epochs\", 5)\n",
    "    mlflow.log_param(\"loss\", \"sparse_categorical_crossentropy\")\n",
    "    mlflow.log_param(\"embedding_dim\", embedding_dim)\n",
    "    mlflow.log_param(\"num_books\", num_books)\n",
    "\n",
    "    model.fit(train_ds, epochs=5, callbacks=[mlflow_callback], validation_data=val_ds)\n",
    "\n",
    "    mlflow.tensorflow.log_model(model, artifact_path=\"two_tower_model\")\n",
    "\n",
    "    \n",
    "    test_users = []\n",
    "    test_true_items = []\n",
    "\n",
    "    for user, true_item in val_ds.take(-1):\n",
    "        test_users.append(user.numpy())\n",
    "        test_true_items.append(true_item.numpy())\n",
    "\n",
    "    test_users = np.array(test_users)\n",
    "    test_true_items = np.array(test_true_items)\n",
    "\n",
    "    ks = [5, 10, 20]\n",
    "    recalls = []\n",
    "    for k in ks:\n",
    "        recall = compute_recall_at_k(model, test_users, test_true_items, k)\n",
    "        recalls.append(recall)\n",
    "        mlflow.log_metric(f\"recall@{k}\", recall)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(ks, recalls, marker=\"o\")\n",
    "    plt.title(\"Recall@K\")\n",
    "    plt.xlabel(\"K\")\n",
    "    plt.ylabel(\"Recall\")\n",
    "    plt.savefig(\"recall_at_k.png\")\n",
    "    plt.close()\n",
    "    mlflow.log_artifact(\"recall_at_k.png\")\n",
    "\n",
    "    print(\"MLflow run completed. Run ID:\", mlflow.active_run().info.run_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1d7a3",
   "metadata": {},
   "source": [
    "Inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
