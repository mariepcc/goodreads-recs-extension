{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d3f3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_USE_LEGACY_KERAS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00b72b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ast import literal_eval\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40f8ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run valuable-worm-769 at: http://ec2-13-61-4-77.eu-north-1.compute.amazonaws.com:5000/#/experiments/0/runs/77413dfda66f465bbe5169271e2aab22\n",
      "üß™ View experiment at: http://ec2-13-61-4-77.eu-north-1.compute.amazonaws.com:5000/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# Test mlflow\n",
    "\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://ec2-13-61-4-77.eu-north-1.compute.amazonaws.com:5000/\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"param1\", 15)\n",
    "    mlflow.log_metric(\"metric1\", 0.89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3873d76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/malcolmosh/goodbooks-10k/master/books_enriched.csv\",\n",
    "    index_col=[0],\n",
    "    converters={\"genres\": literal_eval, \"authors\": literal_eval},\n",
    ")\n",
    "\n",
    "ratings = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/malcolmosh/goodbooks-10k/master/ratings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bfafd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'authors', 'average_rating', 'best_book_id', 'book_id',\n",
       "       'books_count', 'description', 'genres', 'goodreads_book_id',\n",
       "       'image_url', 'isbn', 'isbn13', 'language_code',\n",
       "       'original_publication_year', 'original_title', 'pages', 'publishDate',\n",
       "       'ratings_1', 'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5',\n",
       "       'ratings_count', 'small_image_url', 'title', 'work_id',\n",
       "       'work_ratings_count', 'work_text_reviews_count', 'authors_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85052ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[\n",
    "    [\"book_id\", \"title\", \"description\", \"authors\", \"genres\", \"average_rating\", \"ratings_count\"]\n",
    "    ].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760544a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>authors</th>\n",
       "      <th>genres</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "      <td>WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...</td>\n",
       "      <td>[Suzanne Collins]</td>\n",
       "      <td>[young-adult, fiction, fantasy, science-fictio...</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4780653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "      <td>Harry Potter's life is miserable. His parents ...</td>\n",
       "      <td>[J.K. Rowling, Mary GrandPr√©]</td>\n",
       "      <td>[fantasy, fiction, young-adult, classics]</td>\n",
       "      <td>4.44</td>\n",
       "      <td>4602479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "      <td>About three things I was absolutely positive.\\...</td>\n",
       "      <td>[Stephenie Meyer]</td>\n",
       "      <td>[young-adult, fantasy, romance, fiction, paran...</td>\n",
       "      <td>3.57</td>\n",
       "      <td>3866839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>The unforgettable novel of a childhood in a sl...</td>\n",
       "      <td>[Harper Lee]</td>\n",
       "      <td>[classics, fiction, historical-fiction, young-...</td>\n",
       "      <td>4.25</td>\n",
       "      <td>3198671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>Alternate Cover Edition ISBN: 0743273567 (ISBN...</td>\n",
       "      <td>[F. Scott Fitzgerald]</td>\n",
       "      <td>[classics, fiction, historical-fiction, romance]</td>\n",
       "      <td>3.89</td>\n",
       "      <td>2683664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                              title  \\\n",
       "0        1            The Hunger Games (The Hunger Games, #1)   \n",
       "1        2  Harry Potter and the Sorcerer's Stone (Harry P...   \n",
       "2        3                            Twilight (Twilight, #1)   \n",
       "3        4                              To Kill a Mockingbird   \n",
       "4        5                                   The Great Gatsby   \n",
       "\n",
       "                                         description  \\\n",
       "0  WINNING MEANS FAME AND FORTUNE.LOSING MEANS CE...   \n",
       "1  Harry Potter's life is miserable. His parents ...   \n",
       "2  About three things I was absolutely positive.\\...   \n",
       "3  The unforgettable novel of a childhood in a sl...   \n",
       "4  Alternate Cover Edition ISBN: 0743273567 (ISBN...   \n",
       "\n",
       "                         authors  \\\n",
       "0              [Suzanne Collins]   \n",
       "1  [J.K. Rowling, Mary GrandPr√©]   \n",
       "2              [Stephenie Meyer]   \n",
       "3                   [Harper Lee]   \n",
       "4          [F. Scott Fitzgerald]   \n",
       "\n",
       "                                              genres  average_rating  \\\n",
       "0  [young-adult, fiction, fantasy, science-fictio...            4.34   \n",
       "1          [fantasy, fiction, young-adult, classics]            4.44   \n",
       "2  [young-adult, fantasy, romance, fiction, paran...            3.57   \n",
       "3  [classics, fiction, historical-fiction, young-...            4.25   \n",
       "4   [classics, fiction, historical-fiction, romance]            3.89   \n",
       "\n",
       "   ratings_count  \n",
       "0        4780653  \n",
       "1        4602479  \n",
       "2        3866839  \n",
       "3        3198671  \n",
       "4        2683664  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5173cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4\n",
       "2        2      260       5\n",
       "3        2     9296       5\n",
       "4        2     2318       3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7d7f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_id': <tf.Tensor: shape=(), dtype=int32, numpy=1>, 'book_id': <tf.Tensor: shape=(), dtype=int32, numpy=258>, 'rating': <tf.Tensor: shape=(), dtype=int32, numpy=5>}\n",
      "{'user_id': <tf.Tensor: shape=(), dtype=int32, numpy=2>, 'book_id': <tf.Tensor: shape=(), dtype=int32, numpy=4081>, 'rating': <tf.Tensor: shape=(), dtype=int32, numpy=4>}\n",
      "{'user_id': <tf.Tensor: shape=(), dtype=int32, numpy=2>, 'book_id': <tf.Tensor: shape=(), dtype=int32, numpy=260>, 'rating': <tf.Tensor: shape=(), dtype=int32, numpy=5>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 13:57:36.854256: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ratings_tf = tf.data.Dataset.from_tensor_slices(ratings.to_dict(\"list\"))\n",
    "for x in ratings_tf.take(3):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce529e7",
   "metadata": {},
   "source": [
    "**Query Tower**\n",
    "\n",
    "User Model representing User and his reading history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efab04b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class UserTower(tf.keras.Model):\n",
    "    def __init__(self, unique_book_ids, num_tokens, embedding_matrix, \n",
    "                 user_emb_dim=32, dropout_rate=0.2):\n",
    "        super(UserTower, self).__init__()\n",
    "\n",
    "        self.book_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.IntegerLookup(\n",
    "                vocabulary=unique_book_ids, \n",
    "                oov_token=num_tokens - 1,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim=num_tokens,\n",
    "                output_dim=embedding_matrix.shape[1],  # 1536 for OpenAI embeddings\n",
    "                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                trainable=False,  # freeze OpenAI vectors\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.attention = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=8,\n",
    "            key_dim=embedding_matrix.shape[1] + 1,  # 1536 embedding + 1 rating\n",
    "        )\n",
    "        self.pooling = tf.keras.layers.GlobalAveragePooling1D()\n",
    "\n",
    "        self.final_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(user_emb_dim)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_history = inputs[\"user_history\"]\n",
    "        history_ratings = inputs[\"history_ratings\"]\n",
    "\n",
    "        history_emb = self.book_embedding(user_history)  # (batch, seq_len, 1536)\n",
    "\n",
    "        mean_rating = tf.reduce_mean(history_ratings, axis=1, keepdims=True)  # (batch, 1)\n",
    "        norm_ratings = history_ratings - mean_rating  # (batch, seq_len)\n",
    "        ratings_expanded = tf.expand_dims(norm_ratings, -1)  # (batch, seq_len, 1)\n",
    "        concat_input = tf.concat([history_emb, ratings_expanded], axis=-1)  # (batch, seq_len, 1537)\n",
    "\n",
    "        attn_out = self.attention(concat_input, concat_input)\n",
    "\n",
    "        pooled = self.pooling(attn_out)\n",
    "\n",
    "        user_emb = self.final_layers(pooled)\n",
    "\n",
    "        return user_emb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef878c18",
   "metadata": {},
   "source": [
    "**Testing user tower**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbaa6944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User embeddings shape: (1, 32)\n",
      "User embeddings: [[-9.9997129e-04 -1.7348172e-04  3.2667897e-04 -2.4285991e-04\n",
      "  -4.4389372e-04  7.6807063e-04  1.0735486e-03  1.1163257e-04\n",
      "  -9.2693226e-04 -1.8707567e-04  5.2680302e-04  4.9088581e-04\n",
      "  -3.3586338e-04  1.5380569e-03 -2.1850027e-04  1.9180549e-03\n",
      "   1.6392160e-03 -1.0483534e-03  2.8725556e-04  1.5963594e-04\n",
      "  -7.3438301e-04  7.1609538e-05 -7.0786203e-04  7.1581890e-05\n",
      "  -1.0429180e-03  7.2478200e-04  3.6984694e-04 -5.5364775e-04\n",
      "  -6.6615554e-05 -1.5791173e-03 -1.5890929e-04  1.2531534e-03]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "\n",
    "    data = {\n",
    "        \"user_history\": [1, 2, 3],\n",
    "        \"history_ratings\": [4, 5, 3],\n",
    "    }\n",
    "    embedding_matrix = np.load(\"../src/data/embeddings_matrix.npy\")\n",
    "    num_books, embedding_dim = embedding_matrix.shape\n",
    "    unique_book_ids = np.arange(num_books - 1)\n",
    "\n",
    "\n",
    "    user_tower = UserTower(\n",
    "        unique_book_ids=unique_book_ids,\n",
    "        num_tokens=num_books,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "    )\n",
    "\n",
    "    example = {\n",
    "        \"user_history\": tf.constant([data[\"user_history\"]], dtype=tf.int32),\n",
    "        \"history_ratings\": tf.constant([data[\"history_ratings\"]], dtype=tf.float32),\n",
    "    }\n",
    "\n",
    "    user_embeddings = user_tower(example)\n",
    "\n",
    "    print(\"\\nUser embeddings shape:\", user_embeddings.shape)\n",
    "    print(\"User embeddings:\", user_embeddings.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07416c4",
   "metadata": {},
   "source": [
    "**Candidate Tower**\n",
    "\n",
    "Book Model representing books and its features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f070f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemTower(tf.keras.Model):\n",
    "    def __init__(self, unique_book_ids, num_tokens, embedding_matrix, user_emb_dim=32, dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        self.vocabulary = unique_book_ids\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "\n",
    "        self.book_embedding = tf.keras.Sequential([\n",
    "            tf.keras.layers.IntegerLookup(\n",
    "                vocabulary=unique_book_ids, \n",
    "                oov_token=num_books - 1,\n",
    "                mask_token=None\n",
    "            ),\n",
    "            tf.keras.layers.Embedding(\n",
    "                input_dim=num_tokens,\n",
    "                output_dim=embedding_matrix.shape[1],  \n",
    "                embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "                trainable=False,  \n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        self.rating_norm = tf.keras.layers.Normalization(axis=None)\n",
    "        \n",
    "        self.final_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "            tf.keras.layers.Dropout(dropout_rate),\n",
    "            tf.keras.layers.Dense(user_emb_dim)\n",
    "        ])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        item_embedding = self.book_embedding(inputs[\"book_id\"])\n",
    "        rating_norm = self.rating_norm(inputs[\"avg_rating\"])\n",
    "        rating_norm = tf.expand_dims(rating_norm, -1)\n",
    "        concat_input = tf.concat([item_embedding, rating_norm], axis=-1)\n",
    "\n",
    "        item_emb = self.final_layers(concat_input)\n",
    "        return item_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3f0d99",
   "metadata": {},
   "source": [
    "**Testing candidate tower**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf13d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\Book embeddings shape: (1, 32)\n",
      "Book embeddings: [[ 0.09775109 -0.07769852  0.05263288 -0.03646014 -0.05195387  0.01323555\n",
      "   0.11356245 -0.00553065 -0.06013871 -0.12366802 -0.13854872 -0.00403975\n",
      "   0.02192115  0.24883085 -0.12797149  0.09379776  0.03131978 -0.03375912\n",
      "  -0.01381343  0.14757746 -0.02357512  0.05439571 -0.1077126  -0.0903956\n",
      "   0.11584894 -0.01130453 -0.06477856 -0.09171694  0.10833809 -0.02485837\n",
      "   0.09170313 -0.1164398 ]]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = {\n",
    "        \"book_id\": [1],\n",
    "        \"avg_rating\": [4],\n",
    "    }\n",
    "    embedding_matrix = np.load(\"../src/data/embeddings_matrix.npy\")\n",
    "    num_books, embedding_dim = embedding_matrix.shape\n",
    "    unique_book_ids = np.arange(num_books - 1)\n",
    "\n",
    "    book_tower = ItemTower(\n",
    "        unique_book_ids=unique_book_ids,\n",
    "        num_tokens=num_books,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "    )\n",
    "\n",
    "    example = {\n",
    "        \"book_id\": tf.constant(data[\"book_id\"], dtype=tf.int32), \n",
    "        \"avg_rating\": tf.constant(data[\"avg_rating\"], dtype=tf.float32),\n",
    "    }\n",
    "\n",
    "    book_embeddings = book_tower(example)\n",
    "\n",
    "    print(\"\\Book embeddings shape:\", book_embeddings.shape)\n",
    "    print(\"Book embeddings:\", book_embeddings.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f61926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query book: The Great Gatsby\n",
      "\n",
      "Top similar books:\n",
      "- Babbitt (cosine similarity: 0.652)\n",
      "- Jaws (cosine similarity: 0.635)\n",
      "- David and Goliath: Underdogs, Misfits, and the Art of Battling Giants (cosine similarity: 0.548)\n",
      "- The House of Thunder (cosine similarity: 0.543)\n",
      "- Gone with the Wind (cosine similarity: 0.531)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "id_to_title = dict(zip(books['book_id'], books['title']))\n",
    "\n",
    "# Choose a query book\n",
    "query_id = 5\n",
    "query_title = id_to_title[query_id]\n",
    "query_emb = embedding_matrix[query_id]\n",
    "\n",
    "# Normalize embeddings\n",
    "emb_norm = embedding_matrix / np.linalg.norm(embedding_matrix, axis=1, keepdims=True)\n",
    "query_emb_norm = query_emb / np.linalg.norm(query_emb)\n",
    "\n",
    "# Compute cosine similarity\n",
    "cos_sim = np.dot(emb_norm, query_emb_norm)\n",
    "\n",
    "# Get top-k similar books (excluding the query itself)\n",
    "top_k = 5\n",
    "top_k_idx = np.argsort(-cos_sim)\n",
    "top_k_idx = top_k_idx[top_k_idx != query_id][:top_k]\n",
    "\n",
    "# Print results\n",
    "print(f\"Query book: {query_title}\\n\")\n",
    "print(\"Top similar books:\")\n",
    "for idx in top_k_idx:\n",
    "    print(f\"- {id_to_title[idx]} (cosine similarity: {cos_sim[idx]:.3f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332853c0",
   "metadata": {},
   "source": [
    "**Two Tower Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4904d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRetrievalModel(tfrs.models.Model):\n",
    "    def __init__(self, user_tower, item_tower, candidates_ds):\n",
    "        super().__init__()\n",
    "        self.user_tower = user_tower\n",
    "        self.item_tower = item_tower\n",
    "\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "    metrics=tfrs.metrics.FactorizedTopK(\n",
    "        candidates=candidates_ds.map(item_tower)\n",
    "    )\n",
    ")\n",
    "    def call(self, features):\n",
    "        user_embeddings = self.user_tower({\n",
    "            \"user_history\": features[\"user_history\"],\n",
    "            \"history_ratings\": features[\"history_ratings\"]\n",
    "        })\n",
    "\n",
    "        book_embeddings = self.item_tower({\n",
    "            \"book_id\": features[\"book_id\"],\n",
    "            \"avg_rating\": features[\"avg_rating\"]\n",
    "        })\n",
    "\n",
    "        return user_embeddings, book_embeddings\n",
    "\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        user_embeddings, book_embeddings = self(features)\n",
    "        return self.task(user_embeddings, book_embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b840da",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ae5a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_history': TensorShape([128, 175]), 'history_ratings': TensorShape([128, 175]), 'book_id': TensorShape([128]), 'avg_rating': TensorShape([128])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-08 14:08:27.422964: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ratings = ratings.merge(\n",
    "    books[[\"book_id\", \"average_rating\"]],\n",
    "    on=\"book_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "ratings_tf = tf.data.Dataset.from_tensor_slices({\n",
    "    \"user_id\": ratings[\"user_id\"].values.astype(\"int32\"),\n",
    "    \"book_id\": ratings[\"book_id\"].values.astype(\"int32\"),\n",
    "    \"rating\":  ratings[\"rating\"].values.astype(\"float32\"),\n",
    "    \"avg_rating\": ratings[\"average_rating\"].values.astype(\"float32\"),\n",
    "})\n",
    "\n",
    "# Split users 80/20\n",
    "users = ratings[\"user_id\"].unique()\n",
    "train_cut = int(0.8 * len(users))\n",
    "train_users = tf.constant(users[:train_cut], dtype=tf.int32)\n",
    "val_users   = tf.constant(users[train_cut:], dtype=tf.int32)\n",
    "\n",
    "train_filter = lambda x: tf.reduce_any(tf.equal(x[\"user_id\"], train_users))\n",
    "val_filter   = lambda x: tf.reduce_any(tf.equal(x[\"user_id\"], val_users))\n",
    "\n",
    "# Book lookup table for avg_rating\n",
    "book_avg = tf.lookup.StaticHashTable(\n",
    "    tf.lookup.KeyValueTensorInitializer(\n",
    "        keys=books[\"book_id\"].values.astype(\"int32\"),\n",
    "        values=books[\"average_rating\"].values.astype(\"float32\"),\n",
    "    ),\n",
    "    default_value=0.0,\n",
    ")\n",
    "\n",
    "# Group by user to form history\n",
    "def group_by_user(ds):\n",
    "    return ds.apply(\n",
    "        tf.data.experimental.group_by_window(\n",
    "            key_func=lambda x: tf.cast(x[\"user_id\"], tf.int64),\n",
    "            reduce_func=lambda _, ds: ds.batch(1000),  # large enough\n",
    "            window_size=1000,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Leave-one-out per user\n",
    "def make_example(batch):\n",
    "    book_ids = batch[\"book_id\"]\n",
    "    ratings = batch[\"rating\"]\n",
    "\n",
    "    n = tf.shape(book_ids)[0]\n",
    "\n",
    "    def make_valid():\n",
    "        history = {\n",
    "            \"user_history\": book_ids[:-1],\n",
    "            \"history_ratings\": ratings[:-1],\n",
    "            \"book_id\": book_ids[-1],\n",
    "            \"avg_rating\": batch[\"avg_rating\"][-1],\n",
    "        }\n",
    "        return tf.data.Dataset.from_tensors(history)\n",
    "\n",
    "    def too_short():\n",
    "        empty = {\n",
    "            \"user_history\": tf.constant([], dtype=tf.int32),\n",
    "            \"history_ratings\": tf.constant([], dtype=tf.float32),\n",
    "            \"book_id\": tf.constant(0, dtype=tf.int32),\n",
    "            \"avg_rating\": tf.constant(0.0, dtype=tf.float32),\n",
    "        }\n",
    "        return tf.data.Dataset.from_tensors(empty).take(0)  # empty dataset\n",
    "\n",
    "    return tf.cond(n < 2, too_short, make_valid)\n",
    "\n",
    "\n",
    "# Prepare train/val datasets\n",
    "train_ds = (\n",
    "    group_by_user(ratings_tf.filter(train_filter))\n",
    "    .flat_map(make_example)\n",
    "    .padded_batch(\n",
    "        128,\n",
    "        padded_shapes={\n",
    "            \"user_history\": [None],\n",
    "            \"history_ratings\": [None],\n",
    "            \"book_id\": [],\n",
    "            \"avg_rating\": [],\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "val_ds = (\n",
    "    group_by_user(ratings_tf.filter(val_filter))\n",
    "    .flat_map(make_example)\n",
    "    .padded_batch(\n",
    "        128,\n",
    "        padded_shapes={\n",
    "            \"user_history\": [None],\n",
    "            \"history_ratings\": [None],\n",
    "            \"book_id\": [],\n",
    "            \"avg_rating\": [],\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "# Candidate set for retrieval\n",
    "candidates_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"book_id\": books[\"book_id\"].values.astype(\"int32\"),\n",
    "    \"avg_rating\": books[\"average_rating\"].values.astype(\"float32\"),\n",
    "}).batch(128)\n",
    "\n",
    "# Quick check\n",
    "for batch in train_ds.take(1):\n",
    "    print({k: v.shape for k, v in batch.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "635a1da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch keys: dict_keys(['user_history', 'history_ratings', 'book_id', 'avg_rating'])\n",
      "\n",
      "User history (first example):\n",
      "[ 258  268 5556 3638 1796  867   47 2738 4691  238 2063  916 4614  111\n",
      "   11 1644 3889  136 6665  150   35   33   60  148   10   94    4  492\n",
      "   57 1521   70   42  103   36  138  119   32   13   66 3406 2002   43\n",
      "  287 1041   45   38   67   46   22  115   31   16  132   40  407  256\n",
      "  273  378  329   98  216 1176  140  869 2679 1310  414   54   85  219\n",
      "  177  109  131  102   95  225   76  100  171  179  255  485  325  498\n",
      "  323  162   72  233  496  306  354 1030 1055 2770  198 1761 1942  128\n",
      "   81 5191 1187 2535 3294 4893 1180 6285 2133 1011  262  437  421  143\n",
      "  142  642  901  212    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0]\n",
      "Shape: (175,)\n",
      "\n",
      "History ratings (first example):\n",
      "[5. 3. 3. 3. 5. 3. 3. 3. 4. 2. 4. 3. 1. 3. 5. 5. 3. 5. 4. 3. 5. 4. 3. 3.\n",
      " 4. 1. 5. 2. 3. 5. 5. 3. 3. 4. 2. 3. 4. 4. 4. 2. 5. 4. 3. 5. 5. 2. 3. 4.\n",
      " 3. 3. 4. 3. 3. 2. 2. 3. 3. 3. 4. 3. 3. 4. 3. 4. 3. 4. 4. 3. 3. 4. 5. 3.\n",
      " 4. 5. 4. 4. 3. 4. 3. 2. 1. 4. 3. 4. 3. 4. 3. 4. 3. 3. 3. 4. 4. 4. 4. 4.\n",
      " 3. 5. 5. 4. 5. 5. 5. 3. 4. 4. 5. 4. 3. 4. 5. 5. 4. 4. 4. 3. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n",
      "Shape: (175,)\n",
      "\n",
      "Target book ID (first example):\n",
      "231\n",
      "\n",
      "Target book avg rating (first example):\n",
      "4.14\n"
     ]
    }
   ],
   "source": [
    "# Take one batch from your dataset\n",
    "for batch in train_ds.take(1):\n",
    "    print(\"Batch keys:\", batch.keys())  # what features are in the batch\n",
    "\n",
    "    # Inspect user history for the first example\n",
    "    print(\"\\nUser history (first example):\")\n",
    "    print(batch['user_history'][0].numpy())  # book IDs\n",
    "    print(\"Shape:\", batch['user_history'][0].shape)\n",
    "\n",
    "    # Inspect history ratings for the first example\n",
    "    print(\"\\nHistory ratings (first example):\")\n",
    "    print(batch['history_ratings'][0].numpy())\n",
    "    print(\"Shape:\", batch['history_ratings'][0].shape)\n",
    "\n",
    "    # Target book\n",
    "    print(\"\\nTarget book ID (first example):\")\n",
    "    print(batch['book_id'][0].numpy())\n",
    "\n",
    "    # Target book avg rating\n",
    "    print(\"\\nTarget book avg rating (first example):\")\n",
    "    print(batch['avg_rating'][0].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048bd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://ec2-13-61-4-77.eu-north-1.compute.amazonaws.com:5000/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2be0f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/07 14:51:18 INFO mlflow.tracking.fluent: Experiment with name 'TTM Baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflow-artifacts-123456789012-us-east-1/1', creation_time=1757249478539, experiment_id='1', last_update_time=1757249478539, lifecycle_stage='active', name='TTM Baseline', tags={}>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"TTM Baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b539e39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.40.25-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore<1.41.0,>=1.40.25 (from boto3)\n",
      "  Downloading botocore-1.40.25-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3)\n",
      "  Downloading s3transfer-0.13.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.25->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore<1.41.0,>=1.40.25->boto3) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.25->boto3) (1.17.0)\n",
      "Downloading boto3-1.40.25-py3-none-any.whl (139 kB)\n",
      "Downloading botocore-1.40.25-py3-none-any.whl (14.0 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading s3transfer-0.13.1-py3-none-any.whl (85 kB)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/4\u001b[0m [boto3]32m3/4\u001b[0m [boto3]re]\n",
      "\u001b[1A\u001b[2KSuccessfully installed boto3-1.40.25 botocore-1.40.25 jmespath-1.0.1 s3transfer-0.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b650c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awscli\n",
      "  Downloading awscli-1.42.25-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: botocore==1.40.25 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from awscli) (1.40.25)\n",
      "Collecting docutils<=0.19,>=0.18.1 (from awscli)\n",
      "  Downloading docutils-0.19-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from awscli) (0.13.1)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from awscli) (6.0.2)\n",
      "Collecting colorama<0.4.7,>=0.2.5 (from awscli)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli)\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore==1.40.25->awscli) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore==1.40.25->awscli) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from botocore==1.40.25->awscli) (2.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.40.25->awscli) (1.17.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /Users/marysiapacocha/Desktop/goodreads/goodreads-recs-extension/.venv/lib/python3.10/site-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
      "Downloading awscli-1.42.25-py3-none-any.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: rsa, docutils, colorama, awscli\n",
      "\u001b[2K  Attempting uninstall: rsa\n",
      "\u001b[2K    Found existing installation: rsa 4.9.1\n",
      "\u001b[2K    Uninstalling rsa-4.9.1:\n",
      "\u001b[2K      Successfully uninstalled rsa-4.9.1\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4/4\u001b[0m [awscli]2m3/4\u001b[0m [awscli]a]\n",
      "\u001b[1A\u001b[2KSuccessfully installed awscli-1.42.25 colorama-0.4.6 docutils-0.19 rsa-4.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f10b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528cf2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Access Key ID [None]: ^C\n"
     ]
    }
   ],
   "source": [
    "!aws configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95d1443c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adagrad` runs slowly on M1/M2 Macs, please use the legacy TF-Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adagrad`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.load(\"../src/data/embeddings_matrix.npy\")\n",
    "num_books, embedding_dim = embedding_matrix.shape\n",
    "unique_book_ids = np.arange(num_books - 1)\n",
    "\n",
    "book_ids = books[\"book_id\"].values\n",
    "avg_ratings = books[\"average_rating\"].values.astype(np.float32)\n",
    "\n",
    "candidates_ds = tf.data.Dataset.from_tensor_slices({\n",
    "    \"book_id\": book_ids,\n",
    "    \"avg_rating\": avg_ratings\n",
    "}).batch(128)\n",
    "\n",
    "user_tower = UserTower(\n",
    "        unique_book_ids=unique_book_ids,\n",
    "        num_tokens=num_books,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "    )\n",
    "item_tower = ItemTower(\n",
    "        unique_book_ids=unique_book_ids,\n",
    "        num_tokens=num_books,\n",
    "        embedding_matrix=embedding_matrix,\n",
    "    )\n",
    "\n",
    "# train_ds built from the previous Leave-One-Out + 80/20 split pipeline\n",
    "\n",
    "model = BookRetrievalModel(user_tower, item_tower, candidates_ds)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=[tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\"), tf.keras.metrics.Accuracy(name=\"accuracy\")]\n",
    ")\n",
    "\n",
    "mlflow_callback = tf.keras.callbacks.LambdaCallback(\n",
    "    on_epoch_end=lambda epoch, logs: [mlflow.log_metric(name, value, step=epoch) for name, value in logs.items()]\n",
    ")\n",
    "\n",
    "with mlflow.start_run(run_name=\"book_retrieval_experiment\"):\n",
    "\n",
    "    mlflow.log_param(\"num_books\", num_books)\n",
    "    mlflow.log_param(\"embedding_dim\", embedding_dim)\n",
    "    mlflow.log_param(\"optimizer\", \"Adagrad\")\n",
    "    mlflow.log_param(\"learning_rate\", 0.1)\n",
    "    mlflow.log_param(\"epochs\", 5)\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        epochs=5,\n",
    "        callbacks=[mlflow_callback]\n",
    "    )\n",
    "\n",
    "    mlflow.tensorflow.log_model(model, artifact_path=\"book_retrieval_model\")\n",
    "\n",
    "    print(\"MLflow run completed. Run ID:\", mlflow.active_run().info.run_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1d7a3",
   "metadata": {},
   "source": [
    "Inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.17)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
